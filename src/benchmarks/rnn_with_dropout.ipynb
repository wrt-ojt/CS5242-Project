{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41c95eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673876e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RNN model\n",
    "class TextRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size, num_layers=1, dropout_rate=0.8):\n",
    "        super(TextRNN, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        \n",
    "        # RNN layer\n",
    "        self.rnn = nn.RNN(self.embedding_dim, self.hidden_size, self.num_layers, batch_first=True, dropout=self.dropout_rate)\n",
    "        \n",
    "        # Dropout layer to prevent overfitting\n",
    "        self.dropout = nn.Dropout(self.dropout_rate)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Embedding\n",
    "        embedded = self.embedding(x)\n",
    "        \n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Forward propagate RNN\n",
    "        # _, hidden = self.rnn(embedded, h0)\n",
    "        out, _ = self.rnn(embedded, h0)\n",
    "\n",
    "        # Apply dropout\n",
    "        # hidden = self.dropout(hidden.squeeze(0))\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        \n",
    "        # Pass the output of the last time step to the classifier\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17d66bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset for text files with labels (int[])\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, file_ids, labels, file_dir, tokenizer, word_to_idx, max_length=20):\n",
    "        self.file_ids = file_ids\n",
    "        self.labels = labels\n",
    "        self.file_dir = file_dir\n",
    "        self.tokenizer = tokenizer\n",
    "        self.word_to_idx = word_to_idx\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_id = self.file_ids[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Read text file\n",
    "        file_path = os.path.join(self.file_dir, f\"{file_id}.txt\")\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            # print(\"text:\", text)\n",
    "        \n",
    "        # Normalize and Tokenize\n",
    "        tokens = self.tokenizer.tokenize(text.lower())\n",
    "        \n",
    "        # Convert tokens to indices\n",
    "        indices = [self.word_to_idx.get(token, self.word_to_idx['<UNK>']) for token in tokens]\n",
    "        \n",
    "        # Truncate or pad sequence\n",
    "        if len(indices) > self.max_length:\n",
    "            indices = indices[:self.max_length]\n",
    "        else:\n",
    "            indices = indices + [self.word_to_idx['<PAD>']] * (self.max_length - len(indices))\n",
    "            \n",
    "        return torch.tensor(indices, dtype=torch.long), torch.tensor(label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d52148b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary from all training text files\n",
    "def build_vocabulary(file_paths, tokenizer, min_freq=2, vocab_file='vocabulary_rnn.txt'):\n",
    "    print(\"Building vocabulary...\")\n",
    "\n",
    "    # load vocabulary from file if it exists\n",
    "    if os.path.exists(vocab_file):\n",
    "        print(f\"Vocabulary file {vocab_file} already exists. Loading...\")\n",
    "        word_to_idx = {}\n",
    "        with open(vocab_file, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                word, idx = line.strip().split('\\t')\n",
    "                word_to_idx[word] = int(idx)\n",
    "        return word_to_idx\n",
    "    \n",
    "    # Count word frequencies\n",
    "    word_counts = Counter()\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "        tokens = tokenizer.tokenize(text.lower())\n",
    "        word_counts.update(tokens)\n",
    "    \n",
    "    # Filter words by frequency\n",
    "    words = [word for word, count in word_counts.items() if count >= min_freq]\n",
    "    \n",
    "    # Add special tokens\n",
    "    word_to_idx = {'<PAD>': 0, '<UNK>': 1}\n",
    "    for word in words:\n",
    "        word_to_idx[word] = len(word_to_idx)\n",
    "\n",
    "    # save vocabulary to file\n",
    "    with open(vocab_file, 'w', encoding='utf-8') as f:\n",
    "        for word, idx in word_to_idx.items():\n",
    "            f.write(f\"{word}\\t{idx}\\n\")\n",
    "    print(f\"Vocabulary saved to {vocab_file}\")\n",
    "    \n",
    "    return word_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "436bdf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, device, patience=3, num_epochs=10):\n",
    "    model.to(device)\n",
    "    \n",
    "    best_val_accuracy = 0.0\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        train_predictions = []\n",
    "        train_labels = []\n",
    "        \n",
    "        for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(data)\n",
    "            # print(\"training outputs:\", outputs, \"labels:\", labels)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            loss.backward()\n",
    "\n",
    "            # prevent gradient explosions in RNN\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "            \n",
    "            # Get predictions\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_predictions.extend(predicted.cpu().numpy())\n",
    "            train_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "        \n",
    "        # Calculate training metrics\n",
    "        train_accuracy = accuracy_score(train_labels, train_predictions)\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        val_predictions = []\n",
    "        val_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, labels in val_loader:\n",
    "                data, labels = data.to(device), labels.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(data)\n",
    "                # print(\"outputs:\", outputs, \"labels:\", labels)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                total_val_loss += loss.item()\n",
    "                \n",
    "                # Get predictions\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_predictions.extend(predicted.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        # Calculate validation metrics\n",
    "        val_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "              f'Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, '\n",
    "              f'Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "        \n",
    "        # Early stopping check\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f'Early stopping triggered after {epoch+1} epochs')\n",
    "                break\n",
    "    \n",
    "    # Load the best model state\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return model, best_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ef452f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, labels in test_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            # print(\"data:\", data, \"label:\", labels)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Get predictions\n",
    "            print(\"outputs.data:\", outputs.data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    \n",
    "    print(f'Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.4f}')\n",
    "    return accuracy, avg_loss, all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475ab50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_with_splits(model_type='rnn_with_dropout', train=True):\n",
    "    # Configuration\n",
    "    config = {\n",
    "        'val_split_ratio': 0.15,  \n",
    "        'test_split_ratio': 0.15,\n",
    "        'seed': 42,\n",
    "        'batch_size': 16,\n",
    "        'embedding_dim': 100,\n",
    "        'hidden_size': 128,\n",
    "        'num_layers': 2,\n",
    "        'learning_rate': 0.001,\n",
    "        'num_epochs': 10,\n",
    "        'patience': 3\n",
    "    }\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Initialize NLTK tokenizer\n",
    "    tokenizer = TweetTokenizer()\n",
    "    \n",
    "    # Load labels from CSV\n",
    "    labels_df = pd.read_csv('../../label.csv').dropna(how=\"all\")\n",
    "    print(f\"Loaded {len(labels_df)} labels from CSV\")\n",
    "\n",
    "    df = labels_df.copy().dropna(how='all')\n",
    "    df['ID'] = df['ID'].astype(int)\n",
    "    df['class'] = df['class'].astype(int)\n",
    "    \n",
    "    # # Map label text to numerical values\n",
    "    label_map = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "    # labels_df['text_numeric_label'] = labels_df['text'].apply(lambda x: label_map.get(x.lower(), 0))\n",
    "    \n",
    "    # # Create a dataframe for splitting\n",
    "    # df = labels_df[['ID', 'text_numeric_label', 'label']].rename(columns={'text_numeric_label': 'text_label'})\n",
    "    \n",
    "    # Split the data into train, validation, and test sets\n",
    "    print(\"Splitting data...\")\n",
    "    val_test_size = config['val_split_ratio'] + config['test_split_ratio']\n",
    "    if val_test_size >= 1.0:\n",
    "        print(\"Error: Sum of validation and test split ratios must be less than 1.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Adjust test size relative to the remaining data after validation split\n",
    "    relative_test_size = config['test_split_ratio'] / (1.0 - config['val_split_ratio'])\n",
    "\n",
    "    try:\n",
    "        # Split into train and temp (val + test)\n",
    "        train_df, temp_df = train_test_split(\n",
    "            df,\n",
    "            test_size=val_test_size,\n",
    "            random_state=config['seed'],\n",
    "            stratify=df['label'] # Stratify if labels are imbalanced\n",
    "        )\n",
    "        # Split temp into val and test\n",
    "        val_df, test_df = train_test_split(\n",
    "            temp_df,\n",
    "            test_size=relative_test_size,\n",
    "            random_state=config['seed'],\n",
    "            stratify=temp_df['label'] # Stratify if labels are imbalanced\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error during data splitting: {e}. Check split ratios and data.\")\n",
    "        # Might happen if a label class has too few samples for stratification\n",
    "        print(\"Attempting split without stratification...\")\n",
    "        try:\n",
    "            train_df, temp_df = train_test_split(df, test_size=val_test_size, random_state=config['seed'])\n",
    "            val_df, test_df = train_test_split(temp_df, test_size=relative_test_size, random_state=config['seed'])\n",
    "        except Exception as e_nostrat:\n",
    "            print(f\"Error during non-stratified split: {e_nostrat}.\")\n",
    "            sys.exit(1)\n",
    "    \n",
    "    print(f\"Train set: {len(train_df)} samples\")\n",
    "    print(f\"Validation set: {len(val_df)} samples\")\n",
    "    print(f\"Test set: {len(test_df)} samples\")\n",
    "    \n",
    "    # Create full file paths for building vocabulary\n",
    "    train_ids = train_df['ID'].astype(int).values\n",
    "    val_ids = val_df['ID'].astype(int).values\n",
    "    test_ids = test_df['ID'].astype(int).values\n",
    "    \n",
    "    train_labels = train_df['class'].values\n",
    "    val_labels = val_df['class'].values\n",
    "    test_labels = test_df['class'].values\n",
    "    \n",
    "    # Build vocabulary from training data only to prevent data leakage\n",
    "    file_paths = [f\"../../raw_data/{id}.txt\" for id in train_ids if os.path.exists(f\"../../raw_data/{id}.txt\")]\n",
    "    word_to_idx = build_vocabulary(file_paths, tokenizer)\n",
    "    vocab_size = len(word_to_idx)\n",
    "    print(f\"Vocabulary size: {vocab_size}\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = TextDataset(train_ids, train_labels, '../../raw_data', tokenizer, word_to_idx)\n",
    "    val_dataset = TextDataset(val_ids, val_labels, '../../raw_data', tokenizer, word_to_idx)\n",
    "    test_dataset = TextDataset(test_ids, test_labels, '../../raw_data', tokenizer, word_to_idx)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "    \n",
    "    # Initialize the model based on type\n",
    "    num_classes = 3  # negative (0), neutral (1), positive (2)\n",
    "    # if model_type.lower() == 'lstm':\n",
    "    #     model = TextLSTM(vocab_size, config['embedding_dim'], config['hidden_size'], num_classes, config['num_layers'])\n",
    "    #     print(\"Using LSTM model\")\n",
    "    # else:\n",
    "    model = TextRNN(vocab_size, config['embedding_dim'], config['hidden_size'], num_classes, config['num_layers'])\n",
    "    print(\"Using RNN model\")\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "    \n",
    "    # Train the model if requested\n",
    "    if train:\n",
    "        print(\"Starting training...\")\n",
    "        model, best_val_acc = train_model(\n",
    "            model, \n",
    "            train_loader, \n",
    "            val_loader, \n",
    "            criterion, \n",
    "            optimizer, \n",
    "            device, \n",
    "            patience=config['patience'], \n",
    "            num_epochs=config['num_epochs']\n",
    "        )\n",
    "        \n",
    "        # Save the trained model\n",
    "        model_save_path = f\"{model_type}_text_classifier.pth\"\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'vocab': word_to_idx,\n",
    "            'config': config\n",
    "        }, model_save_path)\n",
    "        print(f\"Model saved to {model_save_path}\")\n",
    "    else:\n",
    "        # Load pre-trained model\n",
    "        model_load_path = f\"{model_type}_text_classifier.pth\"\n",
    "        if os.path.exists(model_load_path):\n",
    "            checkpoint = torch.load(model_load_path, map_location=device)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            print(f\"Loaded pre-trained model from {model_load_path}\")\n",
    "        else:\n",
    "            print(f\"No pre-trained model found at {model_load_path}. Using untrained model.\")\n",
    "    \n",
    "    # Evaluate the model on test set\n",
    "    print(\"Evaluating model on test set...\")\n",
    "    test_accuracy, test_loss, test_predictions = evaluate_model(model, test_loader, criterion, device)\n",
    "    \n",
    "    # Create results dataframe for test set\n",
    "    results = pd.DataFrame({\n",
    "        'ID': test_ids,\n",
    "        'true_label': test_labels,\n",
    "        'predicted_label': test_predictions\n",
    "    })\n",
    "    \n",
    "    # Map numeric labels back to text\n",
    "    reverse_label_map = {v: k for k, v in label_map.items()}\n",
    "    results['true_class'] = results['true_label'].map(reverse_label_map)\n",
    "    results['predicted_class'] = results['predicted_label'].map(reverse_label_map)\n",
    "    \n",
    "    # Save results\n",
    "    results.to_csv(f\"{model_type}_classification_results.csv\", index=False)\n",
    "    print(f\"Results saved to {model_type}_classification_results.csv\")\n",
    "    \n",
    "    return model, test_accuracy, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37f0f237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with RNN model...\n",
      "Using device: cpu\n",
      "Loaded 4511 labels from CSV\n",
      "Splitting data...\n",
      "Train set: 3157 samples\n",
      "Validation set: 1115 samples\n",
      "Test set: 239 samples\n",
      "Building vocabulary...\n",
      "Vocabulary file vocabulary_rnn.txt already exists. Loading...\n",
      "Vocabulary size: 3703\n",
      "Using RNN model\n",
      "Starting training...\n",
      "Epoch [1/10], Batch [10/198], Loss: 0.9113\n",
      "Epoch [1/10], Batch [20/198], Loss: 1.2089\n",
      "Epoch [1/10], Batch [30/198], Loss: 1.2813\n",
      "Epoch [1/10], Batch [40/198], Loss: 0.8517\n",
      "Epoch [1/10], Batch [50/198], Loss: 1.1510\n",
      "Epoch [1/10], Batch [60/198], Loss: 1.0541\n",
      "Epoch [1/10], Batch [70/198], Loss: 1.1767\n",
      "Epoch [1/10], Batch [80/198], Loss: 1.2171\n",
      "Epoch [1/10], Batch [90/198], Loss: 0.8819\n",
      "Epoch [1/10], Batch [100/198], Loss: 0.7134\n",
      "Epoch [1/10], Batch [110/198], Loss: 0.9664\n",
      "Epoch [1/10], Batch [120/198], Loss: 0.8229\n",
      "Epoch [1/10], Batch [130/198], Loss: 0.7945\n",
      "Epoch [1/10], Batch [140/198], Loss: 0.7261\n",
      "Epoch [1/10], Batch [150/198], Loss: 0.8455\n",
      "Epoch [1/10], Batch [160/198], Loss: 1.0328\n",
      "Epoch [1/10], Batch [170/198], Loss: 0.7799\n",
      "Epoch [1/10], Batch [180/198], Loss: 0.9679\n",
      "Epoch [1/10], Batch [190/198], Loss: 0.8853\n",
      "Epoch [1/10], Train Loss: 1.0346, Train Accuracy: 0.5211, Val Loss: 0.9217, Val Accuracy: 0.5946\n",
      "Epoch [2/10], Batch [10/198], Loss: 0.8867\n",
      "Epoch [2/10], Batch [20/198], Loss: 1.1530\n",
      "Epoch [2/10], Batch [30/198], Loss: 1.2243\n",
      "Epoch [2/10], Batch [40/198], Loss: 0.8959\n",
      "Epoch [2/10], Batch [50/198], Loss: 0.8169\n",
      "Epoch [2/10], Batch [60/198], Loss: 0.8339\n",
      "Epoch [2/10], Batch [70/198], Loss: 0.7876\n",
      "Epoch [2/10], Batch [80/198], Loss: 0.8007\n",
      "Epoch [2/10], Batch [90/198], Loss: 1.0697\n",
      "Epoch [2/10], Batch [100/198], Loss: 1.2232\n",
      "Epoch [2/10], Batch [110/198], Loss: 1.2231\n",
      "Epoch [2/10], Batch [120/198], Loss: 0.8625\n",
      "Epoch [2/10], Batch [130/198], Loss: 1.1111\n",
      "Epoch [2/10], Batch [140/198], Loss: 0.7508\n",
      "Epoch [2/10], Batch [150/198], Loss: 1.2664\n",
      "Epoch [2/10], Batch [160/198], Loss: 1.1525\n",
      "Epoch [2/10], Batch [170/198], Loss: 0.7419\n",
      "Epoch [2/10], Batch [180/198], Loss: 0.7225\n",
      "Epoch [2/10], Batch [190/198], Loss: 0.7456\n",
      "Epoch [2/10], Train Loss: 0.9602, Train Accuracy: 0.5686, Val Loss: 0.9193, Val Accuracy: 0.5946\n",
      "Epoch [3/10], Batch [10/198], Loss: 0.8774\n",
      "Epoch [3/10], Batch [20/198], Loss: 1.1714\n",
      "Epoch [3/10], Batch [30/198], Loss: 1.0046\n",
      "Epoch [3/10], Batch [40/198], Loss: 0.8907\n",
      "Epoch [3/10], Batch [50/198], Loss: 0.7355\n",
      "Epoch [3/10], Batch [60/198], Loss: 0.9889\n",
      "Epoch [3/10], Batch [70/198], Loss: 0.7487\n",
      "Epoch [3/10], Batch [80/198], Loss: 0.9193\n",
      "Epoch [3/10], Batch [90/198], Loss: 1.1623\n",
      "Epoch [3/10], Batch [100/198], Loss: 1.0623\n",
      "Epoch [3/10], Batch [110/198], Loss: 1.3850\n",
      "Epoch [3/10], Batch [120/198], Loss: 1.1067\n",
      "Epoch [3/10], Batch [130/198], Loss: 0.9373\n",
      "Epoch [3/10], Batch [140/198], Loss: 0.8486\n",
      "Epoch [3/10], Batch [150/198], Loss: 0.9009\n",
      "Epoch [3/10], Batch [160/198], Loss: 1.0556\n",
      "Epoch [3/10], Batch [170/198], Loss: 0.8470\n",
      "Epoch [3/10], Batch [180/198], Loss: 1.0271\n",
      "Epoch [3/10], Batch [190/198], Loss: 0.8952\n",
      "Epoch [3/10], Train Loss: 0.9391, Train Accuracy: 0.5762, Val Loss: 0.9132, Val Accuracy: 0.5955\n",
      "Epoch [4/10], Batch [10/198], Loss: 0.8736\n",
      "Epoch [4/10], Batch [20/198], Loss: 0.6775\n",
      "Epoch [4/10], Batch [30/198], Loss: 0.9043\n",
      "Epoch [4/10], Batch [40/198], Loss: 1.0368\n",
      "Epoch [4/10], Batch [50/198], Loss: 0.8048\n",
      "Epoch [4/10], Batch [60/198], Loss: 0.9005\n",
      "Epoch [4/10], Batch [70/198], Loss: 0.8683\n",
      "Epoch [4/10], Batch [80/198], Loss: 0.7441\n",
      "Epoch [4/10], Batch [90/198], Loss: 0.6972\n",
      "Epoch [4/10], Batch [100/198], Loss: 0.9318\n",
      "Epoch [4/10], Batch [110/198], Loss: 1.0483\n",
      "Epoch [4/10], Batch [120/198], Loss: 0.7805\n",
      "Epoch [4/10], Batch [130/198], Loss: 0.8548\n",
      "Epoch [4/10], Batch [140/198], Loss: 0.8939\n",
      "Epoch [4/10], Batch [150/198], Loss: 0.5869\n",
      "Epoch [4/10], Batch [160/198], Loss: 1.0493\n",
      "Epoch [4/10], Batch [170/198], Loss: 0.8028\n",
      "Epoch [4/10], Batch [180/198], Loss: 0.7381\n",
      "Epoch [4/10], Batch [190/198], Loss: 1.0362\n",
      "Epoch [4/10], Train Loss: 0.9268, Train Accuracy: 0.5885, Val Loss: 0.9084, Val Accuracy: 0.5955\n",
      "Epoch [5/10], Batch [10/198], Loss: 0.9916\n",
      "Epoch [5/10], Batch [20/198], Loss: 1.0736\n",
      "Epoch [5/10], Batch [30/198], Loss: 0.9027\n",
      "Epoch [5/10], Batch [40/198], Loss: 0.8826\n",
      "Epoch [5/10], Batch [50/198], Loss: 0.9740\n",
      "Epoch [5/10], Batch [60/198], Loss: 0.8309\n",
      "Epoch [5/10], Batch [70/198], Loss: 1.0768\n",
      "Epoch [5/10], Batch [80/198], Loss: 1.1510\n",
      "Epoch [5/10], Batch [90/198], Loss: 1.1379\n",
      "Epoch [5/10], Batch [100/198], Loss: 0.8856\n",
      "Epoch [5/10], Batch [110/198], Loss: 0.7858\n",
      "Epoch [5/10], Batch [120/198], Loss: 0.8328\n",
      "Epoch [5/10], Batch [130/198], Loss: 0.7765\n",
      "Epoch [5/10], Batch [140/198], Loss: 1.0763\n",
      "Epoch [5/10], Batch [150/198], Loss: 1.2191\n",
      "Epoch [5/10], Batch [160/198], Loss: 0.9098\n",
      "Epoch [5/10], Batch [170/198], Loss: 1.1170\n",
      "Epoch [5/10], Batch [180/198], Loss: 1.2742\n",
      "Epoch [5/10], Batch [190/198], Loss: 1.3272\n",
      "Epoch [5/10], Train Loss: 0.9240, Train Accuracy: 0.5831, Val Loss: 0.9315, Val Accuracy: 0.5991\n",
      "Epoch [6/10], Batch [10/198], Loss: 0.9695\n",
      "Epoch [6/10], Batch [20/198], Loss: 0.8249\n",
      "Epoch [6/10], Batch [30/198], Loss: 0.7869\n",
      "Epoch [6/10], Batch [40/198], Loss: 0.9362\n",
      "Epoch [6/10], Batch [50/198], Loss: 0.7008\n",
      "Epoch [6/10], Batch [60/198], Loss: 1.0763\n",
      "Epoch [6/10], Batch [70/198], Loss: 1.1093\n",
      "Epoch [6/10], Batch [80/198], Loss: 1.0610\n",
      "Epoch [6/10], Batch [90/198], Loss: 0.7810\n",
      "Epoch [6/10], Batch [100/198], Loss: 1.0263\n",
      "Epoch [6/10], Batch [110/198], Loss: 0.7929\n",
      "Epoch [6/10], Batch [120/198], Loss: 1.1089\n",
      "Epoch [6/10], Batch [130/198], Loss: 0.9945\n",
      "Epoch [6/10], Batch [140/198], Loss: 0.7715\n",
      "Epoch [6/10], Batch [150/198], Loss: 0.9683\n",
      "Epoch [6/10], Batch [160/198], Loss: 0.8065\n",
      "Epoch [6/10], Batch [170/198], Loss: 0.9451\n",
      "Epoch [6/10], Batch [180/198], Loss: 1.0300\n",
      "Epoch [6/10], Batch [190/198], Loss: 1.0328\n",
      "Epoch [6/10], Train Loss: 0.9213, Train Accuracy: 0.5850, Val Loss: 0.9062, Val Accuracy: 0.5991\n",
      "Epoch [7/10], Batch [10/198], Loss: 1.3077\n",
      "Epoch [7/10], Batch [20/198], Loss: 1.0119\n",
      "Epoch [7/10], Batch [30/198], Loss: 0.9800\n",
      "Epoch [7/10], Batch [40/198], Loss: 0.9431\n",
      "Epoch [7/10], Batch [50/198], Loss: 1.1109\n",
      "Epoch [7/10], Batch [60/198], Loss: 0.8740\n",
      "Epoch [7/10], Batch [70/198], Loss: 0.8418\n",
      "Epoch [7/10], Batch [80/198], Loss: 1.0754\n",
      "Epoch [7/10], Batch [90/198], Loss: 0.8942\n",
      "Epoch [7/10], Batch [100/198], Loss: 0.9580\n",
      "Epoch [7/10], Batch [110/198], Loss: 0.8522\n",
      "Epoch [7/10], Batch [120/198], Loss: 1.0312\n",
      "Epoch [7/10], Batch [130/198], Loss: 1.3863\n",
      "Epoch [7/10], Batch [140/198], Loss: 0.8700\n",
      "Epoch [7/10], Batch [150/198], Loss: 0.8778\n",
      "Epoch [7/10], Batch [160/198], Loss: 0.9014\n",
      "Epoch [7/10], Batch [170/198], Loss: 0.8840\n",
      "Epoch [7/10], Batch [180/198], Loss: 1.0689\n",
      "Epoch [7/10], Batch [190/198], Loss: 0.6841\n",
      "Epoch [7/10], Train Loss: 0.9084, Train Accuracy: 0.5873, Val Loss: 0.9230, Val Accuracy: 0.5955\n",
      "Epoch [8/10], Batch [10/198], Loss: 0.8860\n",
      "Epoch [8/10], Batch [20/198], Loss: 0.8167\n",
      "Epoch [8/10], Batch [30/198], Loss: 1.0342\n",
      "Epoch [8/10], Batch [40/198], Loss: 1.2656\n",
      "Epoch [8/10], Batch [50/198], Loss: 0.9393\n",
      "Epoch [8/10], Batch [60/198], Loss: 1.1251\n",
      "Epoch [8/10], Batch [70/198], Loss: 0.6584\n",
      "Epoch [8/10], Batch [80/198], Loss: 0.8857\n",
      "Epoch [8/10], Batch [90/198], Loss: 0.8662\n",
      "Epoch [8/10], Batch [100/198], Loss: 0.7870\n",
      "Epoch [8/10], Batch [110/198], Loss: 1.0921\n",
      "Epoch [8/10], Batch [120/198], Loss: 0.6860\n",
      "Epoch [8/10], Batch [130/198], Loss: 0.9381\n",
      "Epoch [8/10], Batch [140/198], Loss: 0.8900\n",
      "Epoch [8/10], Batch [150/198], Loss: 1.1444\n",
      "Epoch [8/10], Batch [160/198], Loss: 0.9802\n",
      "Epoch [8/10], Batch [170/198], Loss: 0.6557\n",
      "Epoch [8/10], Batch [180/198], Loss: 1.1335\n",
      "Epoch [8/10], Batch [190/198], Loss: 0.8940\n",
      "Epoch [8/10], Train Loss: 0.9101, Train Accuracy: 0.5841, Val Loss: 0.9047, Val Accuracy: 0.5982\n",
      "Early stopping triggered after 8 epochs\n",
      "Model saved to rnn_text_label_classifier.pth\n",
      "Evaluating model on test set...\n",
      "outputs.data: tensor([[ 0.3318, -0.9611,  0.8850],\n",
      "        [-0.1823, -1.6239,  0.4997],\n",
      "        [-0.0246, -1.6730,  0.8090],\n",
      "        [-0.2363, -2.0705,  0.7739],\n",
      "        [-0.0339, -1.6895,  0.8059],\n",
      "        [-0.0726, -1.4996,  0.6720],\n",
      "        [-0.4699, -2.1524,  0.6242],\n",
      "        [-0.0382, -1.6959,  0.8044],\n",
      "        [-0.5533, -2.0487,  0.5116],\n",
      "        [-0.1258, -1.8509,  0.7782],\n",
      "        [-0.5862, -2.1240,  0.4885],\n",
      "        [-0.0336, -1.6889,  0.8060],\n",
      "        [-0.5191, -2.1423,  0.5643],\n",
      "        [-0.4791, -2.1625,  0.6678],\n",
      "        [-0.0119, -1.6496,  0.8129],\n",
      "        [-0.0346, -1.6906,  0.8057]])\n",
      "outputs.data: tensor([[ 0.7666,  0.4619,  0.6824],\n",
      "        [-0.3641, -2.0268,  0.6530],\n",
      "        [-0.0254, -1.6730,  0.8087],\n",
      "        [-0.0338, -1.6894,  0.8059],\n",
      "        [-0.0337, -1.6892,  0.8060],\n",
      "        [-0.0299, -1.6826,  0.8073],\n",
      "        [-0.4917, -2.0127,  0.5169],\n",
      "        [-0.3861, -2.1967,  0.7392],\n",
      "        [-0.1266, -1.8721,  0.7673],\n",
      "        [-0.0337, -1.6891,  0.8060],\n",
      "        [-0.0341, -1.6898,  0.8058],\n",
      "        [ 0.2031, -0.9999,  0.6668],\n",
      "        [-0.1164, -0.2670,  0.2872],\n",
      "        [-0.0356, -1.6918,  0.8053],\n",
      "        [-0.0332, -1.6883,  0.8061],\n",
      "        [ 0.1442, -0.6450,  0.4262]])\n",
      "outputs.data: tensor([[ 8.5755e-01,  1.1004e+00,  3.2395e-01],\n",
      "        [-4.6739e-01, -2.2372e+00,  6.4523e-01],\n",
      "        [ 7.9276e-01,  5.9850e-01,  6.3690e-01],\n",
      "        [-3.3483e-02, -1.6888e+00,  8.0603e-01],\n",
      "        [-3.3869e-02, -1.6894e+00,  8.0590e-01],\n",
      "        [-2.1076e-02, -1.6667e+00,  8.1018e-01],\n",
      "        [-3.4092e-02, -1.6898e+00,  8.0582e-01],\n",
      "        [-2.4224e-06, -1.6264e+00,  8.1604e-01],\n",
      "        [ 6.6211e-01,  1.5575e+00, -7.5561e-02],\n",
      "        [-4.3975e-01, -2.1806e+00,  6.4872e-01],\n",
      "        [-1.2157e-01, -1.8453e+00,  7.8050e-01],\n",
      "        [-2.8281e-01, -2.0087e+00,  7.5900e-01],\n",
      "        [-3.2300e-02, -1.6869e+00,  8.0649e-01],\n",
      "        [ 7.1892e-01,  1.6922e+00, -6.3257e-02],\n",
      "        [-2.2638e-01, -2.0406e+00,  7.3186e-01],\n",
      "        [-5.5549e-01, -2.2005e+00,  6.4863e-01]])\n",
      "outputs.data: tensor([[-0.0414, -1.7037,  0.7964],\n",
      "        [-0.1632, -1.8886,  0.7657],\n",
      "        [-0.0522, -1.7339,  0.7860],\n",
      "        [ 0.0563, -1.5002,  0.8261],\n",
      "        [ 0.0156, -1.6047,  0.8107],\n",
      "        [-0.6704, -2.3730,  0.6042],\n",
      "        [ 0.0428,  0.2577,  0.1349],\n",
      "        [ 0.3405, -0.9350,  0.8870],\n",
      "        [ 0.5929, -0.2980,  0.8251],\n",
      "        [-0.2717, -1.7760,  0.7204],\n",
      "        [-0.0337, -1.6891,  0.8060],\n",
      "        [-0.1757, -1.7770,  0.6738],\n",
      "        [-0.3755, -2.0448,  0.6242],\n",
      "        [ 0.0144, -1.6216,  0.8087],\n",
      "        [-0.7570, -2.3455,  0.5777],\n",
      "        [-0.3531, -1.8385,  0.6909]])\n",
      "outputs.data: tensor([[-0.0427, -1.3675,  0.6494],\n",
      "        [-0.0338, -1.6893,  0.8059],\n",
      "        [ 0.8565,  0.8368,  0.5507],\n",
      "        [ 0.6987,  0.2044,  0.7447],\n",
      "        [-0.5115, -2.0195,  0.5110],\n",
      "        [ 0.7354,  0.9317,  0.2539],\n",
      "        [-0.5301, -2.2594,  0.7235],\n",
      "        [ 0.1055, -1.4253,  0.8413],\n",
      "        [-0.5120, -2.1468,  0.5233],\n",
      "        [-0.0337, -1.6892,  0.8059],\n",
      "        [-0.0535, -1.7389,  0.7882],\n",
      "        [-0.5856, -2.1907,  0.5291],\n",
      "        [-0.0703, -1.7480,  0.7843],\n",
      "        [ 0.1477, -1.2970,  0.6867],\n",
      "        [ 0.1223, -1.3896,  0.8499],\n",
      "        [-0.1975, -1.7906,  0.6827]])\n",
      "outputs.data: tensor([[ 0.0147, -1.6055,  0.8224],\n",
      "        [-0.0213, -1.6667,  0.8101],\n",
      "        [-0.1816, -1.9193,  0.7287],\n",
      "        [-0.0337, -1.6891,  0.8060],\n",
      "        [-0.0340, -1.6898,  0.8059],\n",
      "        [ 0.4345,  1.0051,  0.0945],\n",
      "        [ 0.0186, -1.5970,  0.8241],\n",
      "        [-0.0202, -1.6548,  0.8036],\n",
      "        [-0.4206, -2.1769,  0.7208],\n",
      "        [-0.0334, -1.6887,  0.8061],\n",
      "        [ 0.7993,  0.6298,  0.6260],\n",
      "        [-0.0649, -1.4637,  0.6544],\n",
      "        [-0.4522, -2.0825,  0.5115],\n",
      "        [ 0.8094,  0.6634,  0.6144],\n",
      "        [-0.7403, -2.4746,  0.5891],\n",
      "        [-0.0378, -1.6958,  0.8047]])\n",
      "outputs.data: tensor([[-0.4321, -1.9843,  0.7189],\n",
      "        [-0.1448, -1.8962,  0.7665],\n",
      "        [-0.4288, -1.9482,  0.5464],\n",
      "        [-0.5552, -2.1582,  0.6143],\n",
      "        [ 0.0022, -1.6240,  0.8170],\n",
      "        [-0.6098, -2.1156,  0.5699],\n",
      "        [ 0.2480, -1.1563,  0.8810],\n",
      "        [-0.0342, -1.6901,  0.8062],\n",
      "        [-0.2760, -2.0586,  0.7472],\n",
      "        [-0.0338, -1.6893,  0.8059],\n",
      "        [-0.0619, -1.7360,  0.7953],\n",
      "        [-0.0471, -1.7369,  0.7816],\n",
      "        [-0.0327, -1.6874,  0.8063],\n",
      "        [-0.5925, -2.0721,  0.5287],\n",
      "        [-0.1653, -1.3562,  0.5361],\n",
      "        [ 0.7065,  0.2344,  0.7379]])\n",
      "outputs.data: tensor([[-5.1177e-02, -1.8195e+00,  8.5077e-01],\n",
      "        [ 1.0493e-03, -1.6373e+00,  8.0811e-01],\n",
      "        [ 4.9009e-02, -1.5396e+00,  8.2961e-01],\n",
      "        [-2.8567e-02, -1.6792e+00,  8.0773e-01],\n",
      "        [-3.3809e-02, -1.6893e+00,  8.0592e-01],\n",
      "        [ 8.7222e-02, -1.4316e+00,  8.0782e-01],\n",
      "        [-3.3286e-02, -1.6884e+00,  8.0610e-01],\n",
      "        [-3.3808e-02, -1.6894e+00,  8.0592e-01],\n",
      "        [-5.4963e-01, -2.3135e+00,  6.1849e-01],\n",
      "        [-3.3231e-01, -2.0761e+00,  6.8050e-01],\n",
      "        [-9.6594e-04, -1.6298e+00,  8.1609e-01],\n",
      "        [-7.8566e-02, -1.7606e+00,  7.8299e-01],\n",
      "        [-2.2551e-02, -1.6695e+00,  8.0982e-01],\n",
      "        [-5.9099e-02, -1.7285e+00,  7.9362e-01],\n",
      "        [-5.0050e-01, -1.9587e+00,  6.9314e-01],\n",
      "        [-3.8295e-02, -1.6921e+00,  7.8844e-01]])\n",
      "outputs.data: tensor([[-0.4307, -2.0086,  0.7206],\n",
      "        [-0.0280, -1.6796,  0.8079],\n",
      "        [-0.0317, -1.6857,  0.8067],\n",
      "        [-0.0338, -1.6892,  0.8059],\n",
      "        [ 0.6939,  0.1830,  0.7516],\n",
      "        [-0.1855, -1.9608,  0.7801],\n",
      "        [ 0.3300,  0.8548,  0.1668],\n",
      "        [ 0.5814,  0.6717,  0.4366],\n",
      "        [-0.0339, -1.6895,  0.8059],\n",
      "        [-0.0357, -1.6925,  0.8053],\n",
      "        [ 0.7439,  0.3825,  0.7014],\n",
      "        [-0.0341, -1.6898,  0.8058],\n",
      "        [-0.0377, -1.6957,  0.8046],\n",
      "        [ 0.0045, -1.6213,  0.8189],\n",
      "        [-0.0337, -1.6891,  0.8060],\n",
      "        [-0.4955, -2.1579,  0.6542]])\n",
      "outputs.data: tensor([[-0.6551, -2.3065,  0.5022],\n",
      "        [-0.0354, -1.6921,  0.8054],\n",
      "        [-0.0335, -1.6888,  0.8060],\n",
      "        [-0.1464, -1.6867,  0.6840],\n",
      "        [-0.4756, -2.1584,  0.5701],\n",
      "        [-0.0326, -1.6873,  0.8063],\n",
      "        [-0.0293, -1.6815,  0.8075],\n",
      "        [-0.0169, -1.5786,  0.7693],\n",
      "        [-0.6047, -2.3262,  0.6035],\n",
      "        [-0.3831, -2.1197,  0.6778],\n",
      "        [-0.4166, -1.9731,  0.6732],\n",
      "        [-0.5284, -2.1495,  0.7039],\n",
      "        [ 0.0354, -1.6100,  0.8019],\n",
      "        [-0.2490, -2.0647,  0.7623],\n",
      "        [-0.0339, -1.6891,  0.8061],\n",
      "        [-0.0351, -1.6915,  0.8055]])\n",
      "outputs.data: tensor([[-0.0337, -1.6892,  0.8059],\n",
      "        [-0.0430, -1.7036,  0.8025],\n",
      "        [-0.4069, -1.9335,  0.4680],\n",
      "        [-0.5942, -2.2063,  0.5916],\n",
      "        [-0.0339, -1.6896,  0.8059],\n",
      "        [-0.4161, -2.2337,  0.7127],\n",
      "        [-0.0563, -1.7233,  0.7961],\n",
      "        [-0.0320, -1.6863,  0.8066],\n",
      "        [-0.1707, -1.9512,  0.7757],\n",
      "        [-0.0396, -1.6980,  0.8038],\n",
      "        [-0.0161, -1.6550,  0.8103],\n",
      "        [-0.4060, -2.1159,  0.6748],\n",
      "        [ 0.8621,  1.1658,  0.2723],\n",
      "        [ 0.8220,  0.7459,  0.5837],\n",
      "        [-0.0340, -1.6897,  0.8059],\n",
      "        [-0.1216, -1.8453,  0.7805]])\n",
      "outputs.data: tensor([[-0.6542, -2.1391,  0.3947],\n",
      "        [-0.0335, -1.6888,  0.8060],\n",
      "        [ 0.4887, -0.5079,  0.8581],\n",
      "        [ 0.8314,  0.8938,  0.5062],\n",
      "        [-0.0369, -1.6942,  0.8049],\n",
      "        [-0.0336, -1.6890,  0.8060],\n",
      "        [-0.5435, -2.0932,  0.5188],\n",
      "        [-0.4343, -2.1168,  0.7248],\n",
      "        [-0.0316, -1.6856,  0.8067],\n",
      "        [ 0.0966, -1.4387,  0.8194],\n",
      "        [-0.4086, -0.9114,  0.1019],\n",
      "        [-0.0073, -1.0870,  0.5423],\n",
      "        [-0.0359, -1.6879,  0.8029],\n",
      "        [-0.4432, -1.9816,  0.5639],\n",
      "        [-0.7690, -2.3545,  0.4264],\n",
      "        [-0.0562, -1.7734,  0.8170]])\n",
      "outputs.data: tensor([[-0.2869, -1.9705,  0.6535],\n",
      "        [-0.6665, -2.4257,  0.6159],\n",
      "        [ 0.8460,  0.8054,  0.5589],\n",
      "        [-0.4988, -2.1585,  0.7309],\n",
      "        [-0.0320, -1.6863,  0.8066],\n",
      "        [-0.2894, -2.0111,  0.7272],\n",
      "        [ 0.4410, -0.6581,  0.8726],\n",
      "        [-0.0530, -1.7162,  0.7958],\n",
      "        [-0.0337, -1.6892,  0.8059],\n",
      "        [-0.5964, -2.2286,  0.3810],\n",
      "        [ 0.6988,  0.2068,  0.7440],\n",
      "        [-0.0309, -1.6844,  0.8070],\n",
      "        [-0.6200, -2.1858,  0.5694],\n",
      "        [-0.1180, -1.8408,  0.7826],\n",
      "        [-0.0346, -1.6906,  0.8057],\n",
      "        [-0.3587, -2.1217,  0.7414]])\n",
      "outputs.data: tensor([[-3.8240e-02, -1.6969e+00,  8.0476e-01],\n",
      "        [-3.1937e-01, -1.8666e+00,  6.7637e-01],\n",
      "        [-4.5136e-02, -1.7083e+00,  8.0194e-01],\n",
      "        [-2.0671e-01, -1.7301e+00,  4.3007e-01],\n",
      "        [-2.6575e-01, -1.8002e+00,  6.0662e-01],\n",
      "        [ 8.5470e-01,  9.5418e-01,  4.8312e-01],\n",
      "        [-4.7572e-02, -1.7116e+00,  8.0084e-01],\n",
      "        [-2.3630e-01, -2.0705e+00,  7.7394e-01],\n",
      "        [-3.7719e-01, -1.9352e+00,  5.7106e-01],\n",
      "        [-5.8522e-01, -2.3233e+00,  4.9208e-01],\n",
      "        [ 6.2702e-01,  1.4293e+00, -8.2183e-02],\n",
      "        [-1.0792e-01, -1.8137e+00,  7.8703e-01],\n",
      "        [-9.6594e-04, -1.6298e+00,  8.1609e-01],\n",
      "        [ 4.3688e-01, -6.8157e-01,  8.8015e-01],\n",
      "        [ 8.3064e-01,  8.9201e-01,  5.0302e-01],\n",
      "        [-5.8873e-01, -2.3548e+00,  6.9288e-01]])\n",
      "outputs.data: tensor([[-0.1799, -1.9600,  0.7731],\n",
      "        [-0.4886, -2.1946,  0.6409],\n",
      "        [ 0.1671, -1.3218,  0.8606],\n",
      "        [ 0.5284,  1.4507, -0.1897],\n",
      "        [-0.0357, -1.6910,  0.8050],\n",
      "        [-0.1501, -1.9034,  0.7773],\n",
      "        [-0.3950, -2.0251,  0.5569],\n",
      "        [-0.0349, -1.6911,  0.8056],\n",
      "        [-0.5663, -2.3311,  0.7038],\n",
      "        [-0.0313, -1.5816,  0.7362],\n",
      "        [ 0.2408, -1.2279,  0.8264],\n",
      "        [-0.0546, -1.7127,  0.7912],\n",
      "        [-0.0337, -1.6891,  0.8060],\n",
      "        [ 0.0379, -1.5826,  0.8394],\n",
      "        [-0.4044, -2.1147,  0.6724]])\n",
      "Test Loss: 0.9148, Test Accuracy: 0.5858\n",
      "Results saved to rnn_with_dropout_classification_results.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing with RNN model...\")\n",
    "rnn_model, rnn_accuracy, rnn_loss = process_data_with_splits(model_type='rnn', train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca9f16b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison of models:\n",
      "RNN - Accuracy: 0.5858, Loss: 0.9148\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nComparison of models:\")\n",
    "print(f\"RNN - Accuracy: {rnn_accuracy:.4f}, Loss: {rnn_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23750444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs5242-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
